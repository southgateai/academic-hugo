---
widget: blank
active: true
author: andy
widget_id: content
headless: true
weight: 12
title: What's here?
subtitle:
design:
  columns: "1"
  background:
    text_color_light: false
    image_darken: 0
    color: ""
---
- It's THE most interesting problem we have to solve: How to coexist with intelligence that first rivals then exceeds our own.
- There's a great deal of fun and profit to be had solving it.
- We can pull apart our entire philosophy in the search to do the right thing in the face of huge unknowns.

We'll cover the engineering side, about the mechanics of how we avoid an AI catastrophe, and it'll be interspersed with some crazy questions we can consider along the way.

What we don't have here is a detailed description of the threat - for that, you need Eliezer's fabulous [AGI (Artificial General Intelligence) Ruin: A List of Lethalities](https://www.alignmentforum.org/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities).  If you're familiar with it, this site is exploring whether point 31 is as clear-cut as it seems.