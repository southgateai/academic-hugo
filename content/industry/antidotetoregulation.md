---
widget: blank
widget_id: antidotetoregulation
headless: true
weight: 3000
title: "Defence as an antidote to regulation"
subtitle:
active: true
design:
  columns: "1"
  background:
    text_color_light: true
    image_darken: 0
    color: black
---

We're already seeing plans for regulation[\[@wiki\]](https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence) in the field of AI, including concrete proposals for law.  The UK's 2021 National AI Strategy [\[@gov.uk\]](https://www.gov.uk/government/publications/national-ai-strategy/national-ai-strategy-html-version) includes this phrase:

> *"However, we take the firm stance that it is critical to watch the evolution of the technology, to take seriously the possibility of AGI and ‘more general AI’, and to actively direct the technology in a peaceful, human-aligned direction."*

The mood music suggests regulation is on the way, and that regulation is likely to arrive long before the AI capability it's intended to regulate.  So several things might happen:

 - Corporations with a vested interest in minimising regulation might propose defensive measures as an alternative.  These would likely be provided, at least in part, by one or more third parties, which themselves are regulated.
 - Governments might make defensive measures mandatory for high-capability AI projects.
 - Telemetry will likely be bundled with defenses to ensure compliance and give advance warning of risk.

Neither of these are bad outcomes compared to uncontrolled AI development, or regulation that slows AI progress in some juristictions, only to allow less cautious operators to get ahead.

This might, and probably should, prove to be such an advantage for the major players in AI that it leads them to fund or create defensive projects themselves.
